[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Preface\n\n\n\n\n\n\n\n\n\nHi! I am Jingwen Wang. I received my bachelor’s degree in Urban Planning and Design from Xi’an Jiaotong-Liverpool University. In the process of learning, I had developed a strong interest in GIS. Therefore, in my graduation thesis, I applied remote sensing and GIS knowledge to do the urban flood risk assessment of Suzhou City. I am currently pursuing a Master’s degree in Urban Spatial Science at UCL CASA. This learning diary is for one of my course: CASA0023 Remotely Sensing Cities and Environment led by Dr. Maclachlan.\nI like watching cartoons in my spare time. My favorite cartoon is Luo XiaoBlack War. It tells the story of a kitten-demon living in the human world. The story is very heartwarming. Sometimes I also try to make little animations myself. I’ve come up with three short stories that I hope to turn into animated films one day.\nAs for my future career planning, I plan to study a second master’s degree in artificial intelligence, and then apply for a PhD to study the application of artificial intelligence in the field of smart cities. I think remote sensing is an important source of data. Learning remote sensing related knowledge and technology can help me realize my academic ideal."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Content",
    "section": "",
    "text": "week1 Introduction to Remote Sensing\nweek2 Portfolio\nweek3 Corrections\nweek4 Policy\nweek6 Google Earth Engine I\nweek7 Classification I\nweek8 Classification II\nweek9 Temperature/SAR"
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "2  week1",
    "section": "2.1 summary",
    "text": "2.1 summary\n\n2.1.1 lecture\nRemote sensing is acquiring information from a distance (NASA).\nThere are two types of sensors, passive and active. Passive sensors Detects reflected energy, which is in electromagnetic waves, from the sun. Human eye, camera, satellite sensor are passive sensors. Active sensors actively emit electromagnetic waves and then waits to receive. Radar, X-ray, LiDAR are active sensors.\n\n\n\n\n\n\n\n\n\nC=velocity of light\nλ=wavelength\nv=frequency\n\n\n\n\n\n\n\n\n\noscillation vs wavelength\n\n\n\n\n\n\n\n\n\nElectromagnetic radiation (EMR) may be absorbed by, transmitted through, and reflected by surface. It could also be scattered by particles in atmosphere.\nElectromagnetic radiation (EMR): waves of an electromagnetic field\nRadiant energy: energy carried by EMR waves\nRadiant flux: energy per unit of time\nShortwave radiation: energy from the sun\nSolar irradiance flux: energy (solar power) from the sun per unit area per unit time\nExitance/emittance flux: energy leaving a surface per unit area per unit time\nThere are three types of atmospheric scattering: Rayleigh (smaller than the wavelength), Mie (same size of wavelength) and non-selective (larger than the wavelength).\nSynthetic Aperture Radar (SAR) can “see through clouds” and collect data at night.\nIn most cases remotely sensed data is raster.\nRemotely sensed data and applications will vary based on the four resolutions: spatial, spectral, temporal, and radiometric. A spectral signature can be discrete (e.g. multi spectral) or continuous (e.g. hyper spectral). Lower the radiometric resolution the lower the quality of the image and possibility to differentiate features.\n\n\n2.1.2 practice\n\n\n\n\n\n\n\n\n\nSentinel and Landsat product of Cape Town in South Africa\n\n\n\n\n\n\n\n\n\nMean and density of band values of the Sentinel"
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "2  week1",
    "section": "2.2 application",
    "text": "2.2 application\nRemote sensing has a wide range of applications. Including but not limited to agriculture, forestry, geoogy, hydrology, sea ice, land cover and land use, oceans and coastal monitoring, atmosphere monitoring, meteorological parametere measured by remote sensing, developing online mapping services and other fields.\nGanesh and Kumar (2013) use this diagram to show some of the applications of remote sensing.\n\n\n\n\n\n\n\n\n\nFan (2020) applied IKONOS remote sensing image as the main data source, extracted ore-controlling factors and mineralization information by image enhancement method, and identified mineral resources. In the images synthesized by bands 3, 2 and 1, the copper mineralization zone presents a narrow strip pattern of gray, blue and blue. The lead-zinc mineralized zone presents a stripe pattern of grayish white, light grayish yellow, and tan tones. This successfully solved the problem of poor natural environment, inconvenient transportation and difficult field geological survey in the west of the West Kunlun Mountains."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "2  week1",
    "section": "2.3 reflection",
    "text": "2.3 reflection\nThrough this week’s lecture, I learned the difference between active sensors and passive sensors, some terms related to remote sensing and four resolutions of remote sensing data: spatial, spectral, temporal, and radiometric. For the practice session, I used remote sensing data from Sentinel and Landsat and visualized their band values.\nI have learned that remote sensing is widely used in many fields. Remote sensing images, for example, can be used to explore for mineral resources.\nThis week is the introduction to the remote sensing course, and I believe that the future learning content will be very rich.\n\n\n\n\nFan, Wang, Yuhai. 2020. “Literate Programming.” Scientific Reports 10 (1): 12309–9. https://doi.org/10.1038/s41598-020-68464-7.\n\n\nGanesh, Senthil, and Niraj Kumar. 2013. “Turnaround Challenges of a State-Owned Enterprise: A Case Study of Orissa Remote Sensing Application Centre, India.” Asian Journal of Management Cases 10: 163–77. https://doi.org/10.1177/0972820113498926."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "3  week2",
    "section": "",
    "text": "This week we learned how to use Xaringan and Quarto book. The following is a ppt about a remote sensing sensor that I made.\n\n\nWarning: package 'xaringanExtra' was built under R version 4.3.2"
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "4  week3",
    "section": "4.1 summary",
    "text": "4.1 summary\nVirginia Norwood designed the Multispectral Scanner which was first used on Landsat 1.\n\n\n\n\n\n\n\n\n\nWhisk broom or spotlight or across track scanners\n\n\n\n\n\n\n\n\n\nLandsat7 and the sensors before it are whisk broom.\n\n4.1.0.1 Part 1: corrections\n1.1 Geometric\nWhen remotely sensed data is collected, image distortions can be introduced due to view angle, topography, wind and rotation of the earth.\nTo match known points in the image and a reference dataset.\nInput to output:\n\n\n\n\n\n\n\n\n\nOutput to input:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe model with the lowest RMSE will fit best.\n1.2 Atmospheric\nTo deal with environmental attenuation caused by atmospheric scattering.\nAdjacency effect of remote sensing image: Through atmospheric scattering, the radiation contribution of non-target pixels to target pixels in remote sensing image.\nThe adjacency effect in remote sensing makes the edge of the object blurred in the remote sensing image, which leads to the passivation and distortion of the remote sensing image.\nIn order to obtain high precision surface parameters, it is necessary to design a method to remove the influence of adjacency effect on target pixels.\nRelative (to something)\nNormalize intensities of different bands within a single image\nNormalise intensities of bands from many dates to one date\nAbsolute(definitive)\nChange digital brightness values into scaled surface reflectance.\nEmpirical Line Correction\n\n\n\n\n\n\n\n\n\n1.3 Orthorectification / Topographic correction\ngeorectification = giving coordinates to an image\northorectification = removing distortions... making the pixels viewed at nadir (straight down)\n\n\n\n\n\n\n\n\n\n1.4 Radiometric calibration\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRadiance refers to any radiation leaving the Earth (i.e. upwelling, toward the sensor.\nIrradiance, is used to describe downwelling radiation reaching the Earth from the sun.\nPart 2: data joining and enhancement\n2.1 Feathering\n“Mosaicking”.\nThe base and second image overlap 20 to 30%.\n2.2 Image enhancement\n\n\n\n\n\n\n\n\n\nContrast enhancement\nBand ratio\nFiltering\nPCA\nImage fusion"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "12  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Fan, Wang, Yuhai. 2020. “Literate Programming.”\nScientific Reports 10 (1): 12309–9. https://doi.org/10.1038/s41598-020-68464-7.\n\n\nGanesh, Senthil, and Niraj Kumar. 2013. “Turnaround Challenges of\na State-Owned Enterprise: A Case Study of Orissa Remote Sensing\nApplication Centre, India.” Asian Journal of Management\nCases 10: 163–77. https://doi.org/10.1177/0972820113498926.\n\n\nMishra, M. K. et al. 2020. “Atmospheric Correction of\nMultispectral VNIR Remote Sensing Data: Algorithm and Inter‐sensor\nComparison of Aerosol and Surface Reflectance Products.”\nEarth and Space Science 7 (9). https://doi.org/10.1029/2019EA000710.\n\n\nOuatiki, Boudhar, H. 2023. “Accuracy Assessment and Bias\nCorrection of Remote Sensing–Based Rainfall Products over Semiarid\nWatersheds.” Theoretical and Applied Climatology 154:\n763–80. https://doi.org/10.1007/s00704-023-04586-y."
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "5  week4",
    "section": "5.1 Summary",
    "text": "5.1 Summary\n\n5.1.1 City - New York\nNew York City’s population is expected to grow to 9 million by 2050. The population is diverse, with whites, blacks, Hispanics and Asians each making up more than 10 percent of the population.\nNew York City’s economy is strong, there are 4.5 million jobs, the gross national product in 1.9 trillion.\nTax is the important source of funds in New York City, New York City will be 40% of the funds for education, housing and economic development.\nThe six core challenges facing New York City are: rising unaffordability, economic insecurity, wealth and health disparities, a climate emergency, failing infrastructure and shifting needs as well as threats to democracy.\n\n\n5.1.2 Policy – OneNYC 2050\nOneNYC 2050 consists of 8 goals: a vibrant democracy, an inclusive economy, thriving neighborhoods, healthy lives, equity and excellence in education, a livable climate, efficient mobility and modern infrastructure.\nThe problem of warming temperatures due to carbon emissions is a major challenge for New York City to achieve its vision of livable climate. The application of remote sensing is expected to solve this problem."
  },
  {
    "objectID": "week4.html#application",
    "href": "week4.html#application",
    "title": "5  week4",
    "section": "5.2 Application",
    "text": "5.2 Application\nRemote sensing technology can help explore the effects of climate change. Zheng et al. (2022) used remote sensing data to explore the impact of climate warming on alpine vegetation.\nUsing Normalized Vegetation Index (NDVI) data from the Global Inventory Model and Mapping Study (GIMMS:1982-2015) and the Moderate Resolution Imaging Spectroradiometer (MODIS: 2000-2020), the maximum greenness of the Asian alpine region (HMA) was revealed. The Snowless Normalized Phenology Index (NDPI) is a 3-band vegetation index designed to best contrast soil and snow cover vegetation for estimating the beginning of the growing season (SOS). The results are important for understanding the response of alpine ecosystems to asymmetric climate warming. This understanding is of great value for pasture management and future vegetation climate prediction."
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "5  week4",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nLivable climate of the city’s vision can be linked with some global goals:\nC40 Cities is committed to helping the world limit global warming to within 1.5 ° C.\nThe Sustainable Development Goals (SDGs) to climate action as The thirteenth.\nBeating the Heat: A Sustainable Cooling faced for Cities of this guide are also concerned about the high temperature problem."
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "4  week3",
    "section": "4.2 Application",
    "text": "4.2 Application\nMishra (2020) introduced an aerosol optical depth (AOD) retrieval and AC algorithm for near-infrared imaging data. For vegetation surface, there is a visible/near-infrared reflectance relationship due to the bsorption of solar radiation by photosynthetic pigments in the visible light band, and the high reflectance in the near infrared band is dominated by the discontinuity of the leaf structure of healthy vegetation. Mishra (2020) uses the retrieved AOD to derive the surface reflectance. A comparison of aerosol and surface reflectance products generated from 106 Cartosat-2S data sets with MODIS-terra products showed that the algorithm significantly eliminated haze from the images, making surface features visible.\n\n\n\n\n\n\n\n\n\nOuatiki (2023) used linear scaling, cumulative distribution function matching, linear regression model and random forest to study the robustness of spatial rainfall product estimates.\n\n\n\n\n\n\n\n\n\nThe figure above shows the original SRP and the five SRPS corrected using deviation correction techniques."
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "4  week3",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nThis week we’re going to learn about corrections. corrections include geometric correction, atmospheric correction, orthorectification/Topographic correction and radiometric calibration. We also learned about data joining and enhancement, including feathering and image enhancement.\nIn the literature review, I learned how to calibrate NIR imaging data and spatial rainfall products.\n\n\n\n\nMishra, M. K. et al. 2020. “Atmospheric Correction of Multispectral VNIR Remote Sensing Data: Algorithm and Inter‐sensor Comparison of Aerosol and Surface Reflectance Products.” Earth and Space Science 7 (9). https://doi.org/10.1029/2019EA000710.\n\n\nOuatiki, Boudhar, H. 2023. “Accuracy Assessment and Bias Correction of Remote Sensing–Based Rainfall Products over Semiarid Watersheds.” Theoretical and Applied Climatology 154: 763–80. https://doi.org/10.1007/s00704-023-04586-y."
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  week 6",
    "section": "6.1 Summary",
    "text": "6.1 Summary\n\n6.1.1 Lecture\nPart 1: The set up of GEE\n1.Terms / jargon specific to GEE\n(1)“Geospatial” processing service\n[1]Geo = Earth’s surface (and near surface)\n[2]Spatial = Any space (not necessarily geographic)\n(2)It permits geospatial analysis at scale\n[1]Scale ?\nmassive datasets\nplanetary scale analysis\nreally quickly (within seconds)\n(2)GEE terms/jargons\nImage = raster\nFeature = vector\nImage stack = ImageCollection\nFeature stack = FeatureCollection\n2.Client vs server side\nClient side – browser\nServer side – where data is stored\n3.Scale (resolution)\nIt refers to pixel resolution.\nPart 2: GEE in action (how we use it)\n1.Buildings blocks of data (the data in GEE)\nRaster data belong to an ImageCollection.\nWe use the specific function to load and manipulate.\n2.Collections, geometries and features\nGeometry = point/line/polygon with no attributes\nFeature = geometry with attributes\nFeature collection = several features with attributes\n3.Reducing images (e.g. zonal statistics)\n[1]var median = collection.reduce(ee.Reducer.median());\n[2] var meanDictionary = image.reduceRegion({\n  reducer: ee.Reducer.mean(),\n  geometry: region.geometry(),\n  scale: 30,\n  maxPixels: 1e9\n});\n\n\n6.1.2 Practice\nIn the practice, I learn how to load data, create points, mosaic and clip images, compute texture and do PCA in GEE. The picture below is the output."
  },
  {
    "objectID": "week6.html#application",
    "href": "week6.html#application",
    "title": "6  week 6",
    "section": "6.2 Application",
    "text": "6.2 Application\nMutanga (2019) pointed out that GEE’s research in vegetation mapping and monitoring, landcovering mapping, agricultural applications, disaster management and earth science and other fields.\n\n\n\n\n\n\n\n\n\nVenkatappa (2021) used Google Earth Engine to assess 40 years of droughts and floods and their impact on farmland and crop production. Using the Palmer Drought Severity Index (PDSI) as a basis for determining drought and flood levels and crop loss levels, crop production losses in the Southeast Asian Monsoon climate zone (MCR) and Equatorial climate zone (ECR) were assessed at grid points with a resolution of 10 × 10 km.\n\n\n\n\n\n\n\n\n\nThe study conducted by Floreano (2021) presents data on deforestation in Brazil between 2009 and 2019 and deforestation that is still likely to occur until 2030. Between 2009 and 2019, the Google Earth Engine platform was the basis for performing LULC evaluations in the Rondonia state via a random forest classifier."
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "6  week 6",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nThis week we focused on learning about Google Earth Engine. In the lecture, I learned GEe-related terms, client and server, and resolution. In my practice class, I did a PCA analysis of an area in India. By reading the literature, I learned that GEE is an expert in vegetation mapping and monitoring, landcovering mapping, agricultural applications, Fields such as disaster management and earth science have wide applications. For example, GEE can be used to measure the damage to farmland caused by droughts and floods. GEE can also monitor changes in land cover over time.\n\n\n\n\nFloreano, L. A. F., I. X. & de Moraes. 2021. “Land Use/Land Cover (LULC) Analysis (2009–2019) with Google Earth Engine and 2030 Prediction Using Markov-CA in the Rondônia State.” Environmental Monitoring and Assessment 193 (4): 239–39.\n\n\nMutanga, L., O. & Kumar. 2019. “Google Earth Engine Applications.” Remote Sensing 11 (591). https://doi.org/10.3390/rs11050591.\n\n\nVenkatappa, M. et al. 2021. “Impacts of Droughts and Floods on Croplands and Crop Production in Southeast Asia – an Application of Google Earth Engine.” The Science of the Total Environment."
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "7  week7",
    "section": "7.1 Summary",
    "text": "7.1 Summary\n\n7.1.1 Lecture\nClassification and regression trees (CART) comprised of classification trees and regression trees\nClassification trees: classify data into two or more discrete categories\nRegression trees: predict continuous dependent variable\nGini impurity: 1-(probability of yes)^2-(the probability of no)^2\n\n\n\n\n\n\n\n\n\nBest model: low bias and low variability\nLow bias = model the real relationship\nLow variability = consistent predictions between datasets\nReply to overfitting: 1. limit minimum number of pixels in a leaf 2. Remove a leaf\nUnsupervised: usually referred to as clustering / also k-means\nPattern vector = all the band values per pixel (could include texture etc)\nPractice\n1.Load vector data\n\n\n\n\n\n\n\n\n\n2.load EO data\n\n\n\n\n\n\n\n\n\n3. clip\nChange the code from:\nvar waytwo_clip = waytwo.clip(shenzhen)\nTo:\nvar waytwo_clip = waytwo.map(function(image){\n  return image.clip(shenzhen);\n});\n4.trainning data\nChange the code from:\n// Sample the composite to generate training data.  Note that the\n// class label is stored in the ‘landcover’ property.\nvar training = waytwo_clip.select(bands).sampleRegions({\n  collection: polygons,\n  properties: [classProperty],\n  scale: 10\n});\nTo:\n// Sample the composite to generate training data.  Note that the\n// class label is stored in the ‘landcover’ property.\nvar waytwo_composite = waytwo_clip.median();\nvar training = waytwo_composite.select(bands).sampleRegions({\n  collection: polygons,\n  properties: [classProperty],\n  scale: 10\n});\n\n\n\n\n\n\n\n\n\n5.classify\nChange code from:\n// Classify the image.\nvar classified = waytwo_clip.classify(classifier);\nTo:\n// Classify the image.\nvar classified = waytwo_composite.classify(classifier);\n\n\n\n\n\n\n\n\n\n6. Train test split\nChange code from:\nWaytwo_clip\nTo:\nWaytwo_composite\n7. Train test split pixel\n\n\n\n\n\n\n\n\n\nApplication\nFauvel (2012) argues that an example of a classification of remote sensing data is land cover classification, which typically uses spectral information as input to a classifier. Some additional spatial information, such as the size of the roof, is used as supplementary information for urban remote sensing image classification. The following is an example of a flat zone classification.\n\n\n\n\n\n\n\n\n\nSchowengerdt (1983) figure out that the first step in the classification program is to train the computer program to recognize the class signature of interest. There are two methods: supervised learning and unsupervised training. Supervised training makes recognition through prior knowledge from field investigations, photographic interpretation, and other sources. Unsupervised training uses a computer algorithm to locate a naturally occurring set of feature vectors from a heterogeneous sample of pixels, and assumes that the computer-specified clusters represent the feature classes in the image for computing class signatures. Classification algorithms are divided into parametric and non-parametric. Parameters assume a particular class statistical distribution, and non-parameters make no assumptions.\n\n\n\n\n\n\n\n\n\nChutia (2016) give a case of hyperspectral remote sensing data classification.\n\n\n\n\n\n\n\n\n\nReflection\nIn this week’s lecture we learned about regression classification trees. You learned what overfitting is and the difference between supervised and unsupervised learning. In this week’s practice, we have used vector and EO data for classification, which uses machine learning methods. In the application module, we will review the classification of multispectral remote sensing images and hyperspectral remote sensing images. And understand two kinds of classification methods and two kinds of classification algorithms.\n\n\n\n\nChutia, D. 2016. “Hyperspectral Remote Sensing Classifications: A Perspective Survey.” Transactions in GIS 20 (4): 463–90. https://doi.org/ 10.1111/tgis.12164.\n\n\nFauvel, M. et al. 2012. “A Spatial–Spectral Kernel-Based Approach for the Classification of Remote-Sensing Images.” Pattern Recognition 45 (1): 381–92.\n\n\nSchowengerdt, R. A. 1983. “Techniques for Image Processing and Classification in Remote Sensing.” Robert A. Schowengerdt."
  },
  {
    "objectID": "week8.html#summary",
    "href": "week8.html#summary",
    "title": "8  week8",
    "section": "8.1 Summary",
    "text": "8.1 Summary\n\n8.1.1 Lecture\nPart 1: Landcover classification (continued)\nOBIA: objected based image analysis\nSuperpixels: consider shapes based on the similarity (homogeneity) or difference (heterogeneity) of the cells\nSimple Linear Iterative Clustering (SLIC) Algorithm for Superpixel generation is the most common method\nCloseness to center: work out spatial distance (from point to center of pixel)\nHomogeneity of colors: color difference (RGB vs RGB to center point)\nCompactness: impact of spatial vs color\nTransform: not on raw data, but to LAB colour space\nSub pixel analysis\nSub pixel classification=spectral mixture analysis (SMA)=linear spectral unmixing\nPart 2: Accuracy\nPA producer accuracy=true positive/(true positive + false negative)\nUA user's accuracy=true positive/(true positive + false positive)\nOverall accuracy=(true positive + true negative)/(true positive +true negative + false positive +false negative)\nTrue positive: model predicts positive class correctly\nTrue negative: model predicts negative class correctly\nFalse positive: model predicts positive, but it is negative\nFalse negative: model predicts negative, but it is positive\n\n\n8.1.2 Practice\n1.vector data\n\n\n\n\n\n\n\n\n\n2.EO data\n\n\n\n\n\n\n\n\n\n3.Accuracy\n\n\n\n\n\n\n\n\n\n4.image\n\n\n\n\n\n\n\n\n\n5.(1)k-means\n\n\n\n\n\n\n\n\n\n(2) Simple non-iterative clustering (SNIC)\n\n\n\n\n\n\n\n\n\n(3) NDVI\n\n\n\n\n\n\n\n\n\nApplication\n1.landcover classification\nQin (2022) introduces four main categories of deep learning models extract information from RS images, including (a) scene classification, which is used to classify image patches and generate scalar values representing one of the scene types; (b) Semantic segmentation, which takes the image patch as input and obtains the ground coverage type of each pixel in the image patch; (c) Object detection that processes image patches to detect object types and generates bounding boxes for each detected object, and (d) object detection that processes image patches to detect object types.\nHayes (2013) use the ensemble Random Forests (RFs) classifier to classify landcover at 1 m resolution using 2009 NAIP imagery in south-eastern Wyoming.\n\n\n\n\n\n\n\n\n\n2.accuracy\n\n\n\n\n\n\n\n\n\nExample based on the above error matrix:\nNumber of correctly classified site: 21 + 31+ 22 = 74    Total number of reference sites = 95\nOverall Accuracy = 74/95 = 77.9%\nProducer’s Accuracy Example based on the above error matrix:\nWater:  Correctly classified reference sites = 21  Total # of reference sites = 33    Producer's Accuracy = 21/33 = 64%\nForest:  Correctly classified reference sites = 31   Total # of reference sites = 39    Producer's Accuracy = 31/39 = 80%\nWater:  Correctly classified reference sites = 22    Total # of reference sites = 23    Producer's Accuracy = 22/23 =96%\nUser’s Accuracy Example based on the above error matrix:\nWater:  Correctly classified sites = 21  Total # of classified sites = 27    User’s Accuracy = 21/27 = 78%\nForest:  Incorrectly classified sites = 31   Total # of classified sites = 37    User’s Accuracy = 31/37 = 84%\nWater:  Incorrectly classified sites = 22    Total # of classified sites = 31    User’s Accuracy = 22/31 = 70%\nReflection\nThis week I learned about land cover classification and accuracy. In the past, I used to mix accuracy and precision. Now I understand that the two terms do not mean exactly the same thing. Precision refers to the user’s accuracy, that is, how well the user can use the data/classification. Corresponding to this is producer’s accuracy, which refers to the producer’s ability to produce data/classification. Their calculation methods are also completely different.\nAt the same time, I found that when using GEE, the same purpose may have more than one way. For example, Spectral unfixing can be obtained in two ways. One is to simply define a variable as the end number; The other is to select some training points to take the average.\n\n\n\n\nHayes, Miller, M. 2013. “High-Resolution Landcover Classification Using Random Forest.” Remote Sensing Letters 5 (2). https://doi.org/10.1080/2150704X.2014.882526.\n\n\nQin, & Liu, R. 2022. “A Review of Landcover Classification with Very-High Resolution Remotely Sensed Optical Images—Analysis Unit, Model Scalability and Transferability.” Remote Sensing 14 (3): 646. https://doi.org/10.3390/rs14030646."
  }
]