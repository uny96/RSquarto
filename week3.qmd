# week3

## summary

Virginia Norwood designed the Multispectral Scanner which was first used on Landsat 1.

```{r echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics('img/01week3.jpg')
```

Whisk broom or spotlight or across track scanners

```{r echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics('img/02week3.jpg')
```

Landsat7 and the sensors before it are whisk broom.

#### Part 1: corrections

1.1 Geometric

When remotely sensed data is collected, image distortions can be introduced due to view angle, topography, wind and rotation of the earth.

To match known points in the image and a reference dataset.

Input to output:

```{r echo=FALSE, out.width='60%', fig.align='center'}
knitr::include_graphics('img/03week3.jpg')
```

Output to input:

```{r echo=FALSE, out.width='60%', fig.align='center'}
knitr::include_graphics('img/04week3.jpg')
```

```{r echo=FALSE, out.width='50%', fig.align='center'}
knitr::include_graphics('img/05week3.jpg')
```

The model with the lowest RMSE will fit best.

1.2 Atmospheric

To deal with environmental attenuation caused by atmospheric scattering.

Adjacency effect of remote sensing image: Through atmospheric scattering, the radiation contribution of non-target pixels to target pixels in remote sensing image.

The adjacency effect in remote sensing makes the edge of the object blurred in the remote sensing image, which leads to the passivation and distortion of the remote sensing image.

In order to obtain high precision surface parameters, it is necessary to design a method to remove the influence of adjacency effect on target pixels.

Relative (to something)

Normalize intensities of different bands within a single image

Normalise intensities of bands from many dates to one date

Absolute(definitive)

Change digital brightness values into scaled surface reflectance.

Empirical Line Correction

```{r echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics('img/06week3.jpg')
```

1.3 Orthorectification / Topographic correction

georectification = giving coordinates to an image

orthorectification = removing distortions\... making the pixels viewed at nadir (straight down)

```{r echo=FALSE, out.width='50%', fig.align='center'}
knitr::include_graphics('img/07week3.jpg')
```

1.4 Radiometric calibration

```{r echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics('img/08week3.jpg')
```

```{r echo=FALSE, out.width='60%', fig.align='center'}
knitr::include_graphics('img/09week3.jpg')
```

Radiance refers to any radiation leaving the Earth (i.e. upwelling, toward the sensor.

Irradiance, is used to describe downwelling radiation reaching the Earth from the sun.

Part 2: data joining and enhancement

2.1 Feathering

"Mosaicking".

The base and second image overlap 20 to 30%.

2.2 Image enhancement

```{r echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics('img/10week3.jpg')
```

Contrast enhancement

Band ratio

Filtering

PCA

Image fusion

## Application

@Mishra20 introduced an aerosol optical depth (AOD) retrieval and AC algorithm for near-infrared imaging data. For vegetation surface, there is a visible/near-infrared reflectance relationship due to the bsorption of solar radiation by photosynthetic pigments in the visible light band, and the high reflectance in the near infrared band is dominated by the discontinuity of the leaf structure of healthy vegetation. @Mishra20 uses the retrieved AOD to derive the surface reflectance. A comparison of aerosol and surface reflectance products generated from 106 Cartosat-2S data sets with MODIS-terra products showed that the algorithm significantly eliminated haze from the images, making surface features visible.

```{r echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics('img/11week3.jpg')
```

@OuatikiBoudharandChehbouni23 used linear scaling, cumulative distribution function matching, linear regression model and random forest to study the robustness of spatial rainfall product estimates.

```{r echo=FALSE, out.width='100%', fig.align='center'}
knitr::include_graphics('img/12week3.jpg')
```

The figure above shows the original SRP and the five SRPS corrected using deviation correction techniques.

## Reflection

This week we're going to learn about corrections. corrections include geometric correction, atmospheric correction, orthorectification/Topographic correction and radiometric calibration. We also learned about data joining and enhancement, including feathering and image enhancement.

1.  **Geometric Correction**: Geometric correction is the process of accurately mapping features in an image to their true locations on the Earth's surface to correct for distortions caused by factors such as the position of the sensor, Earth's curvature, and terrain.

2.  **Atmospheric Correction**: Atmospheric correction involves reducing or eliminating the effects of the atmosphere on remote sensing images. It aims to simulate or remove atmospheric absorption, scattering, and transmission effects to make the images more accurately reflect surface features.

3.  **Orthorectification/Topographic Correction**: Orthorectification refers to adjusting remote sensing images to account for terrain-induced distortions by converting image pixels to geometric coordinates on the ground surface. This correction, which is a type of topographic correction, helps accurately match surface features, particularly in areas with complex terrain.

4.  **Radiometric Calibration**: Radiometric calibration ensures that the digital values in remote sensing images accurately represent the radiometric properties of the objects on the ground. It involves correcting sensor response, removing effects of illumination conditions, atmospheric influences, and sensor characteristics on image brightness values. Radiometric calibration enables quantitative analysis of images, such as estimating surface reflectance or temperature.

In the literature review, I learned how to calibrate NIR imaging data and spatial rainfall products.
